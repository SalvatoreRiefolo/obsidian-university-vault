---
tags: 
  - interactive-3d-graphics
---

Simula un modello di illuminazione globale.

Nell'equazione della riflettanza $L_i$ è data ed è fissa (dipende solo da una sorgente di luce puntiforme da direzione $l$). Inoltre, non c'è occlusione ambientale.
Le sorgenti puntiformi sottostimano l'illuminazione, perché non considera le sorgenti secondarie.

## Ambient light

Soluzione più semplice: si aggiunge una luce costante su tutti i punti di tutte le superfici. Questo però può portare a sovrastimare la luce (alcuni punti dovrebbero ricevere più o meno luce ambientale, come gli angoli che hanno meno direzioni da cui possono ricevere la luce).

Si usa un termine $L_A$ costante da usare al posto di $L_i(p, l)$ nell'[[4. Physically-based shading#Equazione della riflettanza|equazione della riflettanza]] per calcolare la luce ambientale in ogni punto. 
L'effetto della luce ambientale dipende dalla BRDF. Ad esempio, con BRDF Lambertiana, la luce emessa da un punto è definita da 

$$L_o(p,v) = c_{diff} \cdot L_A$$

Tutti i punti su una superfice Lambertiana sono ugualmente luminosi.

Il **colore ambientale** $c_{amb}$ viene differenziato dal colore diffusivo ma per le superfici Lambertiane, $c_{amb} = c_{diff}$.

## Environment mapping

Facendo variare $L_i$ di direzione in direzione (ma senza farla dipendere da altri punti) otteniamo un effetto più realistico di illuminazione ambientale. 

$L_i$ è data da una tabella di lookup (**environment map**, rappresentabile come texture) che mappa la luce che incide su ogni punto. La luce dipende solo dalla direzione, e non dalla posizione sulla superfice (= illuminazione infinitamente lontana). L'accesso alla tabella viene effettuato attraverso la direzione del vettore di vista riflesso.

Si può pensare come un'immagine a 360° presa da un punto qualunque della scena

## Reflection mapping

Uso una BRDF che simula uno specchio perfetto.

$$L_o(v) = F(n, r) L_i(r)$$

$L_o$ è diverso da zero su un'unica direzione, quando la direzione è $r$ (la direzione della luce coincide con la direzione di riflessione, che a sua volta dipende da angolo di vista e normale).

La direzione di $r$ si può identificare con due angoli (elevazione ed azimuth) ed $L_i$ può essere registrata come una texture bidimensionale $\Rightarrow$ queste due componenti di $r$ vengono usate per leggere da un environment map il valore di $L_i$ associato.

### Limitazioni

Gli oggetti riflessi sono sempre infinitamente distanti, e non cambiano dimensione se l'oggetto che riflette si sposta.

Non funziona bene sulle superfici piatte (hanno solo una direzione di riflessione, quindi l'intera superfice riceve lo stesso colore).

Infine non ci sono riflessioni dell'oggetto stesso (solo l'ambiente rappresentato dalla texture pre-calcolata viene riflesso).

## Tipi di mappe ambientali (riflessione speculare)

I punti in queste mappe sono rappresentati tramite valori sRGB o floating-point. Possono essere create a partire da foto o renderizzate durante la scena.

### Cube map
L'immagine a 360° viene rappresentata come 6 foto nella direzione delle facce di un cubo. Questo tipo di mappa non è distorta. Per accedere a un texel della mappa si usano le coordinate $s,t,r$ che rappresentano una direzione dal centro del cubo.

### Equirectangular lat-long map
"Planisfero spalmato" su una superfice rettangole, introduce delle distorsioni.

### Sphere mapping
Si mappa l'ambiente come se fosse vista da una sfera riflessiva perfetta posta al centro della scena. Introduce delle distorsioni.

## Refraction mapping

Se si calcola una mappa di refrazione rispetto a quella di riflessione si possono simulare oggetti trasparenti.

## Environment mapping con BRDF generica

Una superfice solitamente ha componente sia diffusiva che riflessiva. Bisognerebbe integrare su tutte le direzioni, ma è troppo oneroso. 

Si usano **pre-filtered environment map** che pre-calcolano l'integrale per la radianza uscente (invece che la radianza entrante). Il risultato è una texture 4D (colore, angolo di vista, direzione di vista, direzione della lue e radianza entrante) che sarebbe sarebbe troppo grande.
Occorre quindi rimuovere la dipendenza di due parametri per ottenere una texture 2D.

Per una **BRDF diffusa** non abbiamo dipendenza dall'angolo di vista e dal colore del punto (che sono costanti): otteniamo quindi una texture che dipende solo da direzione della luce e radianza entrante, chiamata **irradiance environment map**. L'accesso a questa matrice viene fatto attraverso la normale $n$ nel punto.

$$E(n) = \frac{1}{\pi} \int_{l \in \Omega} L_i(l)(n \cdot l) dl$$
$$L_o(n) = c_{diff} E(n)$$

dove:
- $E(n)$ è l'**irradianza**, la somma di tutti i contributi di luce da tutte le direzioni. Questo valore dipende dalla normale $n$ di un punto, che si usa per accedere al valore salvato nella texture.
- $L_i$ è l'environment map originale.

Le IEM sono versioni sfocate delle EM e possono essere salvate con una risoluzione molto più bassa. Posso quindi prendere i livelli più alti (più piccoli) di una mipmap della IM per ottenere la IEM.

Si possono seguire lo stesso procedimento per avere una pre-filtered EM con una BRDF glossy. La convoluzione è fatta su un lobo più piccolo rispetto alla BRDF diffusa (dove la convoluzione è fatta sull'intera semisfera). Anche in questo caso si può usare un livello intermedio della mipmap dell'EM originale.