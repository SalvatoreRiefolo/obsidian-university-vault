Blending in due passi: prima superfici opache, poi superfici trasparenti (per applicare eventuali blending).

1. **Flat shading**: valutato per primitiva (triangolo).
2. **Gourand shading**: valutato per vertice.
3. **Phong shading**: valutato per pixel.

## Aliasing

"Scalettatura" causata dalla discretizzazione delle primitive reali (coordinate *x, y*) sui pixel.
Di norma, un pixel prende il valore della superfice che lo interseca se il suo centro è nella superfice. 

### Supersampling
Si prendono più sample per pixel, e si usa la media dei sample per definire il colore (ad esempio, se il colore è 100 ed interseco due sample, genero due frammenti con quel colore: durante il blending, il pixel prenderà colore 50).

### FSAA (Full Scene AntiAliasing)
Il rendering della scena viene fatto a risoluzione più alta (2x su ogni dimensione) e si fa la media dei sample vicini. Richiede più spazio nel frame buffer.
In alternativa, si renderizza 4 volte con un offset orizzontale/verticale di 0.5 pixel ogni volta. Richiede più tempo.

### MSAA (MultiSampling AntiAliasing)
Calcola lo shading una sola volta per pixel (invece che 4). Il numero di campioni determina la trasparenza del frammento.

### FXAA (Fast Approximate AntiAliasing)
Post processing su immagine creata, che attraverso medie applica smoothing (appianamento differenze di colore) all'immagine.

## Trasparenza

### Screen door transparency
Aggiungo una bit mask a scacchiera sulle superfici trasparenti per dare l'effetto di trasparenza. Funziona solo con due oggetti.

### Alfa blending
Il canale alfa determina l'opacità del frammento, 1 = opaco, 0 = interamente trasparente. Per rendere un oggetto trasparente si renderizza DOPO gli oggetti opachi (il colore va mischiato con i colori dietro), usando un alfa inferiore a 1.
Si calcola con l'operatore *over*:

$$c_o = \alpha_s c_s + (1- \alpha_s)c_d$$

Con $c_s$ colore dell'oggetto trasparente e $c_d$ è il colore della base.
L'operazione non è commutativa, e mescola (somma) i colori degli oggetti.

### Trasparenza e z-buffer
Si fa il depth testing ma non si aggiorna il buffer, per impedire che gli oggetti trasparenti sovrascrivano quelli opachi. Se più oggetti trasparenti si sovrappongono, il colore finale dipende dall'ordine di questi (alfa blending non commutativo).

## Texture
Processo che prende una superfice e modifica la sua apparenza usando immagini/funzioni/altre sorgenti.

Non si calcola l'equazione di shading, il colore del pixel è presa da un'immagine di riferimento.
Le texture possono avere più dimensioni per avere effetti diversi (1d: color map, 3d: incavature...)

Le coordinate del modello vengono mappate in coordinate *uv* in range [0,1] che fanno riferimento alla texture.

Le textures possono anche essere usate in sostituzione a parametri per il calcolo della riflettanza:
ad esempio, si può avere una texture per il colore speculare, una per il colore diffusivo, ed una per la ruvidezza.

### Funzione di proiezione
L'obiettivo è generare coordinate texture: la funzione associata ad un punto trasforma le coordinate dallo spazio del punti in coordinate *uv*. Alcune funzioni sono *sferica* e *cilindrica*.

### Funzione corresponder
Prende in input la coordinata *uv* e la porta in texture space (pixel). Normalmente sta al modellatore associare ad i vertici di un modello le coordinate texture corrispondenti.

Le coordinate *uv* sono in range $[0,1]$, ed al di fuori di questo range la funzione corresponder determina il comportamento da adottare per la mappatura usando diverse tecniche di **texture wrap**: la texture può essere ripetuta, ripetuta specularmente, o "stretchata" ponendola su un angolo ed allungando l'ultimo pixel sui lati liberi (default).

L'output di una funzione corresponder generalmente è una tripla RGB o una quadrupla RGBa, che rappresenta il colore nel punto *uv* della texture; altre informazioni possono essere codificate, come la ruvidezza della superfice.

## Magnificazione e minificazione

Se una texture deve essere applicata ad un area maggiore rispetto alla dimensione in texel (***magnificazione***) della texture, si può usare un filtro bilineare (interpolazione lineare di quattro texel adiacenti) per ottenere un effetto migliore.

Il caso opposto (***minificazione***) si può gestire sempre tramite interpolazione lineare, ma è limitato: posso interpolare al massimo 4 texel per ottenere il valore di un pixel. Si possono usare vicinati più grandi per l'interpolazione ma il calcolo diventa oneroso. Idealmente si vorrebbe integrare il contributo di ogni texel sul pixel, ma ciò è computazionalmente costoso.


## Mipmapping
La soluzione al problema di minificazione è usare il ***mipmapping***: si calcola preventivamente la texture per diverse distanze, partendo da una texture di grandi dimensioni e facendo **downsampling** (usando filtri adatti, come il Gaussiano) dimezzando le dimensione fino a raggiungere 1 texel. La dimensione totale di queste texture è $< 2 n$, con $n$ dimensione della texture $n \times n$.

Si precalcolano le texture per essere viste a varie distanze, e si creano $n$ versioni in cui ogni versione è un quarto della precedente, fino a dimensione 1 texel. Si sceglie la versione in cui il rapporto pixel/texel è circa 1.

## Summed Area Table
Salvo trasformazione dell'immagine (SAT) in cui per ogni pixel calcolo la somma di tutti i texel della texture nel rettangolo in alto a sinistra rispetto al pixel corrente.

## Interpolazione iperbolica
L'interpolazione per ottenere le coordinate texture per i frammenti dovrebbe essere effettuata in view space, ma le texture si applicano in screen space (dopo la divisione prospettica). Bisogna quindi usare ***l'interpolazione iperbolica*** per interpolare le coordinate texture dalle coordinate uv.