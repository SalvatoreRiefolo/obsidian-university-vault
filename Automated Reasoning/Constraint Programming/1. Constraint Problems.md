### Constraint Satisfaction Problem

Un **problema di soddisfazione dei vincoli** è una tripla $\langle \mathcal{V}, \mathcal{D}, C\rangle$ dove: 
- $\mathcal{V} = \{V_1, \dots, V_n \}$ insieme di **variabili**
- $\mathcal{D} = \{D_1, \dots, D_n \}$ inisieme di **domini**
- $C$ insieme di **vincoli** sulle variabili $\mathcal{V}$. Un **vincolo** $c \in C$ sulle variabili $\mathcal{V}$ è una **relazione** sui domini $\mathcal{D}$: $c \subseteq D_1 \times \dots \times D_n$.

Si cercano una o tutte le possibili **soluzioni**, ossia gli assegnamenti
$$\sigma : \mathcal{V} \rightarrow D_1 \cup \dots \cup D_n$$

tali che che soddisfano tutti i domini e tutti i vincoli. Formalmente:
- $\forall i, \sigma(V_i) \in D_i$
- $\forall c \in C, \langle \sigma(V_{i_1}), \dots, \sigma(V_{i_m})\rangle \in c$


### Constraint Optimization Problem

Un **problema di soddisfazione dei vincoli** è una quadrupla $\langle \mathcal{V}, \mathcal{D}, C, f\rangle$ dove:
- $\mathcal{V} = \{V_1, \dots, V_n \}$ insieme di **variabili**
- $\mathcal{D} = \{D_1, \dots, D_n \}$ inisieme di **domini**
- $C$ insieme di **vincoli** sulle variabili $\mathcal{V}$
- Una **funzione** $f : D_1 \times \dots \times D_n \rightarrow \mathbb{A}$

Si cercano uno o tutti gli assegnamenti
$$\sigma : \mathcal{V} \rightarrow D_1 \cup \dots \cup D_n$$
del CSP che **minimizzano** o **massimizzano** il valore di $f$.

### Insieme di ricerca
L'insieme di ricerca è l'insieme delle **n-tuple** ottenute dal prodotto dei domini, all'interno del quale si cercano i valori che soddisfano i vincoli. 
L'insieme di ricerca è generalmente rappresentato come un albero, l'**albero di ricerca**.

Una prima soluzione al CSP è **generare e testare** tutti i possibili assegnamenti alle variabili. In questo modo, occorre visitare tutto l'albero di ricerca (se si vogliono trovare tutti gli assegnamenti, o come caso peggiore della ricerca di un assegnamento).

### Da COP a CSP e viceversa
$\Rightarrow$ Intuitivamente, se ho una soluzione per un COP ho anche una soluzione per il CSP equivalente, definendo la funzione $f$ come costante.
$\Leftarrow$ Si definisce un limite superiore approssimato per la funzione, e tramite bisezione riduciamo il limite finché non identifichiamo il minimo. 

Generalmente, risolvere CSP è più facile che risolvere COP: a volte per semplificare la risoluzione di un COP ci si può accontentare di soluzioni buone ma non minime.

### Complessità
 CSP è NP-Hard. Possiamo ad esempio ridurre il problema CSP a 3-Coloring.

## Risoluzione CSP

### SAT

Dati
 - Un insieme di variabili booleane $X_1, \dots, X_n$ con domini $D_1, \dots, D_n = \{0, 1\}$
 - Una formula proposizionale $\phi$ in CNF con queste variabili, dove ogni elemento è una variabile o la negazione di una variabile

Il problema $SAT$ consiste nel decidere l'esistenza di un assegnamento delle variabili che soddisfa la formula.

Una formula proposizionale CNF è un **CSP** ed ogni clausola è un **vincolo**: essendo $SAT$ NP-completo ogni problema in NP (come CSP) può essere ridotto ad un istanza di $SAT$. Tuttavia la riduzione potrebbe non essere immediata.

$SAT$ può essere efficientemente usato per risolvere problemi stabili e con numeri "piccoli".

### Local Search

Per risolvere **COP** si possono adottare tecniche di **ricerca locale**: data una possibile soluzione l'algoritmo ispeziona la frontiera dell'albero in cerca di una soluzione più efficiente. 

Esistono diverse tecniche per esaminare la frontiera (anche chiamata **vicinato**), tutte basate su scelte casuali.

Local search può anche essere applicato a **CSP**, rimuovendo vincoli (facilitando così l'ottenimento di una prima soluzione) e definendo una **funzione di penalità** che cresce con ogni vincolo non rispettato. Se la funzione raggiunge l'optimum 0, allora tutti i vincoli sono rispettati.

I vincoli sono divisi in due categorie:
- **Hard constraint**: vanno soddisfatti in **tutte le soluzioni del CSP**. Questo insieme non dovrebbe essere **mai** vuoto.
- **Soft constraint**: possono non essere soddisfatti, ma portano a penalità per la funzione $f$.

Definito l'algoritmo per trovare la soluzione iniziale, si definisce la funzione $N(\sigma)$ che calcola il vicinato di una soluzione $\sigma$, ossia l'insieme delle possibili soluzioni raggiungibili da  $\sigma$. 
Possibilmente il vicinato è definibile con una nozione di **mossa**, ad esempio il cambio di valore di due variabili.
Infine, occorre anche definire come scegliere la mossa successiva, come esplorare il vicinato, come evitare cicli...

### ILP