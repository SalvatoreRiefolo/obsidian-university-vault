
## Complessità deterministica

Come per gli algoritmi, vogliamo calcolare la complessità temporale e spaziale di **problemi**: nello specifico, si prenderanno in considerazione problemi **decisionali**, ossia problemi il cui output è nell'insieme $\{yes, no\}$.

Un linguaggio $L \subseteq \Sigma^*$ è ***deciso*** da una k-MdT se $\forall x \in \Sigma^*$:
- $M(x) = yes$ se $x \in L$
- $M(x) = no$ se $x \notin L$, 

Un linguaggio $L \subseteq \Sigma^*$ è ***accettato*** da una k-MdT se $\forall x \in \Sigma^*$:
- $M(x) = yes$ se $x \in L$
- $M(x)\uparrow$ (non termina) se $x \notin L$, 

Intuitivamente, se esiste una MdT che decide il linguaggio $L$ allora esiste anche una macchina che accetta il linguaggio $L$.

### Complessità temporale $TIME(f(n))$
Una classe di complessità è definita come $C = \{ L | L$ tale che... $\}$.
In particolare si dice che un linguaggio $L$ è **decidibile in $TIME(f(n))$** se esiste una k-MdT $M$ che decide $L$ operando in tempo $f(n)$.

La classe di complessità $P$ è definita come $P = \bigcup\limits_{k \in \mathbb{N}}TIME(n^k)$

### Speed up theorem
Dato $L \in TIME(f(n))$ esiste una k-MdT $M$ che decide $L$ e opera in tempo $f'(n) = \varepsilon \cdot f(n) + n + 2$. Questo significa che esiste un valore $\varepsilon$ vicino a 0 che è in grado di abbassare $f(n)$: la complessità dunque è indipendente da costanti moltiplicative.

>[! Esempio]
>$f(n) = 100n^2 + 10n$ 
>
>Scegliendo un parametro $\varepsilon$ vicino a zero (es: $\frac{1}{100}$) otteniamo che:
>
>$f'(n) = n^2 + \frac{1}{10}n + n + 2$
>
>La complessità rimane invariata: $TIME(100n^2) = TIME(n^2)$

Intuitivamente si può pensare di processare in un singolo "macro" step più di un simbolo per ridurre le costanti moltiplicative.

### Complessità spaziale $SPACE(f(n))$
Il tempo usato deve essere almeno pari allo $spazio$ usato, poiché per usare spazio abbiamo bisogno di investire tempo.

Per classificare la complessità spaziale consideriamo la quantità di celle usate durante la computazione: tutte le celle raggiunte durante la computazione contano verso il calcolo della complessità spaziale. 
Non è necessario calcolare la dimensione dell'input e dell'output, in quanto questi possono arrivare ed essere prodotti on demand.

> [! Esempio]
> Si consideri il problema di decidere se una stringa è palindroma.
> - Per 1-MdT non consumiamo spazio oltre a quello di input: lo spazio usato è $O(n)$.
> - Per 2-MdT copiamo l'input sul secondo nastro, quindi allochiamo $|x| = n$ bits: lo spazio usato è $O(n)$.
> - Per 3-MdT, possiamo tenere in memoria sul secondo nastro due simboli alla volta per effettuare il confronto ed un counter sul terzo: lo spazio usato è $O(\log(n))$

Formalmente, si definisce la complessità spaziale $SPACE(f(n)) = \{L \in \Sigma^* | \exists$ *a k-TM che decide L ed utilizza spazio al più* $f(n)\}$, dove $n = |x|$.

Considerando sempre l'esempio dei palindromi, abbiamo che le sue complessità sono:
$$Palindromes \in SPACE(\log n)$$
$$Palindromes \in TIME(n)$$

Da notare che le due macchine decidono ***Palindromes*** con queste complessità sono **due MdT diverse**!

## Complessità non deterministica

Data una [[2. Modelli Computazionali#Macchina di Turing non deterministica ($N$-MdT) | MdT non deterministica]]  $N$ questa **accetta** una stringa $x$ se e solo se $\exists(s, \triangleright, x) \rightarrow^*(yes,\dots)$, cioè se dalla configurazione iniziale si raggiunge **almeno una** configurazione con stato $yes$.

$N$ **non accetta** una stringa $x$ se e solo se $\forall x \neg(\exists(s, \triangleright, x) \rightarrow^*(yes,\dots))$, cioè se dalla configurazione iniziale non si raggiunge **nessuna** configurazione con stato $yes$.

$N$ opera in tempo $f(n)$ se e solo se $\forall x$ $N$ ha complessità di tempo al più $f(|x|)$.

>[! Esempio]
>1. $SAT = \{\varphi | \varphi$ *is satisfiable*$\}$
>
>Usando MdT $M$ la macchina deve provare tutte i possibili assegnamenti delle variabili: la complessità è almeno esponenziale ($\Omega(2^{n^k})$).
>
>Usando N-MdT $N$ ha complessità polinomiale ($O(n^k)$).
>
> 2. $Reachability$ = dato $G = (V, E)$ diretto e $u,v \in V$ decidere se esiste un percorso da $u$ a $v$.
> 
> In entrambi i casi la complessità temporale è $n^k$; la complessità spaziale per la macchina non deterministica è $SPACE(\log n)$ poiché mantiene in memoria solo un contatore del numero di nodi visitati ($< bin(n) = \log n)$, rispetto a quella deterministica ($SPACE(n\log n)$) dove teniamo in memoria la lista di nodi raggiunti dal nodo iniziale, ognuno di dimensione $\log(n)$.
> 
> $$Reachability \in NP = \bigcup\limits_{k\in\mathbb{N}} NTIME(n^k)$$
> $$Reachability \in NL = NSPACE(\log n)$$

Le principali classi di complessità sono:

$$P = \bigcup\limits_{k\in\mathbb{N}} TIME(n^k), 
NP = \bigcup\limits_{k\in\mathbb{N}} NTIME(n^k)$$


$$EXP = \bigcup\limits_{k\in\mathbb{N}} TIME(2^{n^k}),
NEXP = \bigcup\limits_{k\in\mathbb{N}} NTIME(2^{n^k})$$

$$L = SPACE(\log n), NL = NSPACE(\log n)$$

### Teoremi

1. **Ogni MdT è anche una N-MdT**: quella con grado di non determinismo 1.
Da questo segue che

$$P \subseteq NP, EXP \subseteq NEXP, L \subseteq NL$$

2. Ogni N-MdT $N$ che lavora in tempo $f(n)$ può essere simulata da una MdT $M$ in tempo $O(c^{f(n)})$. Intuitivamente, simuliamo ogni ramo del grafo che rappresenta $N$ usando $M$. Il numero di rami dipende dal grado di non determinismo $d$ di $N$ che è dato dall'insieme di cardinalità massima di $\Delta$ fissati $q, \sigma$, ed è $d^{f(n)}$. Ognuna di queste simulazioni è di $O(f(n))$ steps.

## Halting problem

Vogliamo codificare una MdT $M$ in modo tale da poterla passare come input (insieme ad un input $x$) ad una MdT universale $u$. Per far ciò possiamo rappresentare i simboli come numeri interi codificati in binario:

- $\Sigma \rightarrow 1, \dots, |\Sigma|$
- $K \cup \{y,n,h\} \rightarrow |\Sigma| + 1, \dots,|\Sigma| + |K| + 3$. Da notare che $|\Sigma| + 1$ è lo *stato iniziale*.
- $\{\leftarrow, \rightarrow, -\} \rightarrow |\Sigma| + |K| + 4, \dots$ 
- Encode all tuples of $\delta: (q, \delta, q', \delta', H)$

### Linguaggio Halting
Il linguaggio contiene tutte le macchine che su un certo input terminano.

$$H = \{(M, x) | M(x)\downarrow\}$$

Questo linguaggio **non è decidibile**.

Per dimostrare questa affermazione, assumiamo di avere una macchina $M_H(M,x)$ che decide $H$: la macchina restituisce 0 se $M$ su input $x$ non termina, altrimenti restituisce 1.

Ora consideriamo una macchina $D$, che data in input una MdT $M$ restituisce 1 se $M_H(M,M) = 0$, e non termina se $M_H(M,M) = 1$.

Possiamo vedere come la macchina $D$ generi contraddizioni se il suo input è la codifica della macchina $D$ stessa:
- Se $D(D) = 1$, allora $M_H(D,D) = 0$, ma ciò vorrebbe dire che $D,D$ non termina.
- Se $D(D)$ non termina, allora $M_H(D,D) = 1$, ma ciò vorrebbe dire che $D$ termina.

La macchina $M_H$ non può quindi esistere.

## Classi di complessità

### Funzione di complessità propria
Una funzione di complessità $f: \mathbb{N} \rightarrow \mathbb{N}$ si dice **propria** se:
1. $f$ è non decrescente
2. $f$ è calcolabile da una MdT $M_f$ che usa $O(n + f(n))$ tempo e $O(f(n))$ spazio.

Spazio e numero di step impiegati **non dipendono** dall'input $x$ ma solo dalla sua lunghezza.

Una macchina si dice *precisa* se esegue esattamente $f(n)$ steps usando spazio $g(n)$ per ogni possibile input di lunghezza $n$.
Se $M$ lavora in tempo $f(n)$ e $f$ è propria allora esiste una macchina $M$ che simula $M$ ed è precisa. Possiamo ottenere questa macchina usando $M$ come clock per contare esattamente $f(n)$ steps.

### Classi complemento
Una classe di complessità è un insieme di linguaggi, ed un linguaggio è un sottoinsieme di tutte le possibili stringhe $\Sigma^*$.

Data una classe di complessità $C = \{L | \dots\}$ il suo complemento $\overline C$ è definito come $\overline C = \{\overline L | \dots\}$. In altre parole, la classe complemento per classi di problemi decisionali restituisce $yes$ quando la classe $C$ restituisce $no$ e viceversa.

La classe complemento di $TIME(n^2)$ è uguale alla classe stessa: se inverto $yes,no$ nella definizione di $TIME(n^2)$, la macchina opera comunque nello stesso tempo. La domanda equivalente a $x \in \overline L$ è $x \notin L$.

Per quanto riguarda le macchine non deterministiche invece la domanda è aperta: dato che N-MdT che decide un linguaggio in tempo $f(n)$ deve raggiungere almeno uno stato contenente $yes$, ipotizzando di avere nell'albero di computazione dei percorsi che raggiungono stati contenenti $no$ la semplice inversione di $yes$ con $no$ non basta: la nuova macchina accetta il linguaggio anche se non dovrebbe.

### Hierarchy theorem
Lo hierarchy theorem è una versione quantitativa dell'halting problem. Il teorema dichiara che, data $f$ propria:

$$TIME(f(n)) \subset TIME(f(n)^3)$$

Per dimostrare il teorema, vogliamo dimostrare due proprietà del linguaggio $H_f = \{(M,x) |M(x) = yes$ dopo al massimo $f(|x|) + 5|x| + 4$ steps$\}$:

1. $H_f \in TIME(f(n)^3)$
2. $H_f \notin TIME(f(\lfloor \frac{n}{2}\rfloor))$

Per dimostrare **1.** usiamo una macchina $M_{H_f}$ che decide se $(M,x) \in H_f$.
Si usa la macchina precisa equivalente a $M$ per generare su un nastro una lista di simboli $\sqcap$ in tempo $f(|x|) + 5|x| +4$.
Dopo di che $M_{H_f}$ inizia a simulare $M$, e dopo ogni step cancella un simbolo $\sqcap$. La rappresentazione di $M$ e $x$ si trova su un altro nastro e ha dimensione $n = |M| + |x| + 1$.

Il tempo per generare la sequenza di $\sqcap$ è $O(f(|x|) + |x|)$ (si ricorda che $f$ è propria).
La simulazione di uno step di $M$ richiede un numero costante di scansioni del nastro di input: $O(k \cdot f(n))$ e $k$ è vincolato da $f(n)$, dunque la complessità per la scansione per effettuare un singolo step è $O(f(n)^2)$.
Per simulare $f|x| + 5|x| +4$, il tempo impiegato è $O(f(n)^3)$.

---

Dimostriamo **2.** per contraddizione: si ipotizzi quindi l'esistenza di una macchina $M^*_{H_f}$ che decide $H_f$ in tempo $f(\lceil \frac{n}{2}\rceil)$.

Si consideri la macchina $D$ che termina con $yes$ se e solo se $M^*_{H_f}$ termina con $no$, ossia che:
- $M(M)$ termina con no,
- $M(M)$ non termina,
- $M(M)$ termina dopo $f(|x|) + 5|x| + 4$ steps.

$D$ effettua $5|M| + 4$ step per produrre $M;M$ e $f(\lfloor (\frac{M;M}{2}) \rfloor)$ per simulare la macchina (l'input $n$ è la codifica di $M$ su input $M$, cioè $M;M$). $D$ impiega dunque tempo $5|M| + 4 + f(|M|)$.

Si consideri l'esecuzione di $D$ su input $D$:
- Se $D(D) = no$ allora $M^*_{H_f}(D;D) = yes$ e quindi $D(D) = yes$
- Se $D(D) = yes$ allora $M^*_{H_f}(D;D) = no$, oppure non termina, oppure impiega più di  $f(|x|) + 5|x| + 4$ steps, violando quanto affermato in precedenza.

---

Possiamo derivare due corollari:
1. $TIME(f(n)) \subsetneq TIME(f(2n +1)^3)$. Dai due teoremi possiamo derivare che $n = \frac{m}{2} \rightarrow m \leq 2n + 1$
2. $P \subsetneq EXP$

Dal secondo corollario possiamo anche derivare che
$$P = \bigcup\limits_{k \in \mathbb{N}}TIME(n^k)
\subseteq TIME(2^n)
\subsetneq TIME(2^{n+1})^k
\subseteq TIME(2^{n^2})
\subseteq\bigcup\limits_{k \in \mathbb{N}}TIME(2^{n^k})
= EXP$$

### Gap theorem
Il teorema descrive ciò che accade quando le funzioni di complessità usate non sono proprie. Questo limite alle funzioni usate per descrivere la complessità è necessario in quanto la scelta di funzioni arbitrarie porterebbe a risultati "strani", come il seguente.

Esiste una funzione $f$ **calcolabile** non propria tale che 
$$TIME(f(n)) = TIME(2^{f(n)})$$

Per la dimostrazione, consideriamo:
- Un'enumerazione di MdT $M_0, M_1, \dots, M_h$ , incluse quelle che non terminano su alcuni input.
- Un predicato $P(i, k)$ che è vero per tutte le MdT con indice minore di $i$ e per tutti gli input la cui dimensione è $|x| = i$, tali che terminano **in meno** di $k$ steps o **in più** di $2^k$ steps o **non terminano**. Il predicato è decidibile: possiamo generare tutte le macchine, generare tutti gli input e simulare la macchina sull'input.
- $N(i)$ è il numero di tutti possibili input per tutte le macchine aventi input tra $0$ e $i$. Si può definire come $\sum_{j = 0}^i |\Sigma_j|^i$. 
- $f(i) = k_l$

Per definire $f(i)$ consideriamo la sequenza di intervalli $k_1 = 2 \cdot i, k_2 = 2^k + 1, \dots, k_{j+1} = 2^{k_j} + 1$. La sequenza è divergente e gli intervalli diventano man mano più grandi.

Considerando la macchina $M_h, h < i$ su input $|x| = i$ , $M_h(x)$ termina in $t_h(x)$ steps o diverge (non termina). Il numero di steps $t_h(x)$ cade **sicuramente** in uno degli intervalli sopra definiti.
Se consideriamo $N(i) + 1$ intervalli del tipo $[k_j, k_{j+1})$ esiste almeno un intervallo in cui **nessun** $t_h(x)$ cade, poiché abbiamo al massimo $N(i)$ possibili valori ed ognuno cade in un solo intervallo. Esiste quindi $P(i, k_l) = True$. $k_l$ è il valore che viene assegnato alla funzione $f(i)$ quando il predicato vale $True$.

Per dimostrare che $TIME(f(n)) \supseteq TIME(2^{f(n)})$ (l'altra inclusione è triviale), prendiamo un linguaggio $L \in TIME(2^{f(n)})$: esiste una $M_j$ che decide $L$ in tempo al più $2^{f(n)}$ steps.
Consideriamo un input $x$ tale che $|x| \geq j$. Dato che $P(|x|, f(|x|)) = True$, $M_j(x)$ termina o in $f(|x|)$ steps o in più di $f(2^{f(|x|)})$.
Dato che $x \in L$, il secondo caso non è possibile, quindi $M_j$ opera in $f(n)$ steps, e quindi $L \in TIME(f(n))$.


### Altri teoremi
Se $f$ è una funzione propria allora:

1. $TIME(f(n)) \subseteq NTIME(f(n))$
2. $SPACE(f(n)) \subseteq NSPACE(f(n))$
3. $TIME(f(n)) \subseteq SPACE(f(n))$
4. $SPACE(f(n)) \subseteq TIME(c^{f(n) + \log n})$
5. $NTIME(f(n)) \subseteq SPACE(f(n))$

L'altezza dell'albero rappresentate i vari percorsi della N-MdT $N$ è al più $f(n)$. Possiamo simulare $N$ con una k-MdT $M$ usando un nastro per memorizzare il ramo dell'albero attualmente visitato; in un altro nastro manteniamo un indice che rappresenta la scelta non deterministica allo step corrente, che è nell'intervallo $[1,d]$ con $d < f(n)$ il grado di non determinismo. Lo spazio usato da $M$ è quindi $O(d \cdot f(n) + f(n)) = O(f(n))$ .

6. $NSPACE(f(n)) \subseteq TIME(c^{f(n) + \log n})$

Usiamo $Reachability$ sull'albero della N-MdT con I/O $N$. Indichiamo con $G(N, x)$ il grafo delle computazioni di $N$ dato $x$: ogni nodo è una **configurazione**, ed ogni edge è uno **step computazionale**. Consideriamo un grafo invece che un albero poiché più nodi possono avere lo stesso genitore (più computazioni portano alla stessa configurazione).
$N$ accetta $x$ se e solo se in $G(N,x)$ viene raggiunto un nodo della forma $(yes,\dots)$.

Per simulare $Reachability$ su $N$ con una MdT $M$ dobbiamo:
- generare il grafo $G(N,x)$
- controllare che dalla configurazione iniziale si raggiunga un nodo  $(yes,\dots)$.

Per rappresentare il grafo serve spazio

$$N= (Q, \Sigma, s, \Delta) \rightarrow (2 + |Q|)\cdot (|x|+2) \cdot |\Sigma|^{2(k-2) \cdot f(|x|)}$$

La dimensione del grafo è data da (in ordine): l'insieme degli stati + $yes$ e $no$, la posizione del cursore, il contenuto dei $k-2$ nastri di lavoro di $N$ (al massimo $f(n)$ dato che lavora in tempo $f(n)$). È possibile semplificare la dimensione in 

$$\alpha^{\log n + f(n)}$$

portando la posizione del cursore ($|x|$ ad esponente, questo diventa $\log n$).

$Reachability$ è decidibile in tempo polinomiale rispetto alla dimensione del grafo. $M$ ha quindi complessità $O(C^{\log n + f(n)})$.

### Teorema di Savitch e metodo $Reachability$

$$Reachability \in SPACE((\log n)^2)$$

Introduciamo un predicato $Path(x,y,i)$ che vale $true$ se e solo se esiste un percorso da $x$ a $y$ di lunghezza al più $2^i$.
Ad esempio $Path(x,y,0)$ indica che $x$ e $y$ sono lo stesso nodo o esiste un edge tra i due.
Se $Path(x,y,i+1)$ è vero, allora sono anche veri $Path(x,z,i)$ e $Path(z,y,i)$.
Il grafo è composto da $|V|$ nodi: dato che $|V| = 2^{\log|V|}$, $i$ è al massimo $log|V|$.

Dato che la distanza massima tra due nodi è $log|V|$, il predicato $Path(x,y,\log |V|)$ è vero se e solo $x$ raggiunge $y$ nel grafo. La procedura per effettuare il controllo tiene in memoria un nodo intermedio $z$ di dimensione $log|V|$ per chiamata ricorsiva, ed effettua al più $log|V|$ chiamate. 
Lo spazio usato è quindi $O((\log |V|)^2)$ = $O((\log n)^2)$, con $n$ dimensione del grafo.

---

Come corollario segue che per ogni $f(n) \geq \log n$, $NSPACE(f(n)) \subseteq SPACE(f(n)^2)$: possiamo usare $Reachability$ con una MdT per esaminare il grafo di esecuzione di una N-MdT. 
La complessità potrebbe essere superiore se si considera anche la generazione del grafo, che ha dimensione $\alpha^{f(n)}$, cadendo così in complessità esponenziale. Tuttavia questo non è il caso in quanto il grafo $G$ può essere generato on demand usando spazio $O(f(n))$.

### Teorema di Immerman-Szelepcsenyi
Dato un grafo $G$ ed un nodo $x$, il numero di nodi raggiungibili da $x$ è calcolabile in $NSPACE(\log n)$. 
Il teorema mostra che le classi di complessità di spazio non deterministico sono chiuse sotto complementazione.

Intuitivamente, si compone l'insieme di nodi raggiungibili da $x$ in $i$ steps, chiamato $S(i)$, a partire dal set creato nello step $i-1$.
Non possiamo però memorizzare l'insieme (lo spazio necessario sarebbe $O(n\log n)$): si memorizza quindi la sua **cardinalità**, che richiede $\log n$ bits.

Per fare ciò, dato $k$ che varia tra $1$ e $n-1$ si calcola $|S(k)|$ a partire da $|S(k - 1)|$.
Il calcolo avviene controllando l'appartenenza di tutti i nodi nell'insieme: se il nodo è nell'insieme, si incrementa un contatore.
Il controllo dell'appartenenza viene fatto controllando se il nodo $u$ appartiene all'insieme raggiunto nello step precedente o se esiste un nodo $v$ appartenente all'insieme precedente che raggiunge $u$.
Questo controllo viene a sua volta fatto in maniera **non deterministica**: per tutti i nodi $v$ del grafo si *indovina* se $v$ è nell'insieme $S(k-1)$, e se lo è si incrementa un contatore, modificando anche il valore di una variabile booleana; se una volta esaminati tutti i nodi la cardinalità dell'insieme $S(k-1)$ è uguale al contatore si restituisce la variabile booleana che indica l'appartenenza, altrimenti la computazione fallisce.

Tutti i contatori ed i nodi da controllare hanno dimensione $\log n$, quindi il problema appartiene a $NSPACE(\log n)$.

---

Un corollario mostra che per le funzioni di complessità $f(n) \geq \log n$ $co-NSPACE(f(n) = NSPACE(f(n))$.

Intuitivamente, data una N-MdT $N$ che decide $L$ in spazio $f(n)$ possiamo costruire, fissato un input $x$ il grafo delle computazioni $G(N,x)$.
Sappiamo che $x \in L$ se e solo se un nodo $(yes,\dots)$ è raggiungibile. Dunque per decidere $x \in \overline L = x \notin L$ dobbiamo controllare che un nodo $(yes,\dots)$ **non** sia raggiungibile.

Consideriamo una N-MdT $N'$ che usa il grafo $G(N,x)$ per calcolare $|S(\dots)|$. Se durante la computazione incontriamo un nodo $(yes,\dots)$, terminiamo con $no$; se $S(|G|)$ viene raggiunto senza incontrare nodi $(yes,\dots)$, terminiamo con $yes$.
Questa macchina opera in spazio $O(log(|G(N,x)|)$. Sappiamo che il grafo $G(N,x)$ ha dimensione $\alpha^{f(n)+ \log n}$, quindi la macchina opera in spazio $O(log(\alpha^{f(n)+ \log n})) = O(f(n))$.