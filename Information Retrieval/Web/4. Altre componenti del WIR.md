---
tags: 
  - information-retrieval
---

I cammini casuali non sono un modello fedele dell'utente che naviga il web. Tante componenti rendono questi cammini meno casuali e il modello non permette di esprimere i passi all'indietro (ad esempio, il pulsante "indietro").

Il ranking viene attribuito come combinazione di rank di topicalità ([[2. TF.IDF|tf.idf]], [[3. Modello probabilistico#BM 25 (Best Match 25)|BM25]]) e popolarità ([[3. Analisi dei link per il ranking#PageRank|PageRank]]).

### Altri usi per HITS
L'algoritmo può essere usato nello **stemming**: un nodo raggiunge un altro nodo se quando vengono unite si forma una parola.
HITS permette di dividere i nodi in buoni **prefissi** (hubs) e buoni **suffissi** (autorità). Buoni prefissi raggiungono buoni suffissi.

### Analisi delle reti sociali
Misurano le relazioni tra le persone.
Un grafo rappresenta le persone (nodi) e le loro relazioni (archi). 

- Un **ponte locale** di grado $k$ è un arco tra nodi che sarebbero altrimenti lontani (distanti $k$ nodi). 
- Un **ponte globale** è un arco che se rimosso sconnette la rete.
- Un **weak tie** è un arco che appartiene a pochi triangoli del grafo. Spesso sono ponti globali e rimuovendoli il grafo potrebbe diventare sconnesso.
- Un **strong tie** è un arco che appartiene a molti triangoli. Rimuovendoli le distanze tra i nodi non cambiano molto.

### Spam
L'obiettivo è sfruttare gli algoritmi dei SE a proprio vantaggio.

Esistono diverse tecniche, tra cui lo **spam di parole chiave** e la restituzione di pagine fittizie ai crawler per alterare l'indicizzazione. Queste tecniche venivano usate nella prima generazione di SE.

Nella seconda generazione di SE sono emerse altre tecniche che utilizzano prevalentemente i **link** (linking mutuale, link nascosti, link con testi ingannevoli) e i **robot** (click e query simulati).

Esistono diverse tecniche **anti-spam** che eseguono analisi sulle pagine attraverso euristiche, filtri o machine learning per limitare il problema.

### Search Engine Optimization

Ottimizzazione dei siti web per favorire il ranking della pagina. Le ottimizzazioni sono suddivisibili **ottimizzazioni per l'utente** e **ottimizzazioni per il SE**. Lo scopo è mantenere l'utente sul sito, attraverso una pagina facilmente navigabile e con contenuti di qualità. Molti altri fattori (velocità di caricamento della pagina, recapiti...) giocano verso la qualità di un sito.

Per quanto riguarda l'ottimizzazione per i SE, la quantità e la prossimità delle keywords unite ad un uso adeguato del markup può portare a valutazioni migliori per il ranking. Anche la presenza di link da e verso altri siti influisce su di esso.

### Duplicati

Gran parte delle pagine web è **duplicata** o **replicata** (>2 copie).
Questa duplicazione è spesso legittima ed è da tenere in conto per il corretto funzionamento dei SE, in quanto le pagine duplicate aumentano le risorse usate e sono poco apprezzate dagli utenti.

Esistono inoltre i **mirrors**, che contengono lo stesso contenuto esposto attraverso server diversi. Questo è spesso necessario per questioni di disponibilità e load balancing. I mirrors possono essere usati per ottimizzare le operazioni di crawling e garantire ridondanza se un host fosse non raggiungibile.

### Componenti di un search engine

Oltre ai [[1. Web Information Retrieval#Architettura di un Search Engine|tre componenti principali]], un search engine è dotato di:

- **Web server** che mantiene gli URL e li passa al crawler.
- **[[5. Crawling| Crawler]]** che recupera le pagine e le invia allo store server.
- **Store server** che comprime le pagine e le salva in una **repository**.
- **URL Resolver** che legge i file anchor, converte gli URL da relativi ad assoluti e genera il database dei link con i documenti associati.
- **PageRank** usa il database dei link per calcolare il PageRank dei documenti.
- **Sorter** e **searcher**.