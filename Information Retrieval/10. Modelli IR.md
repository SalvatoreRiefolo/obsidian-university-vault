Un modello è un approccio generale per la risoluzione di un problema.
Nel caso dell'IR, un modello definisce:
1. **Retrieval**: come le informazioni vengono recuperate
2. **Ranking**: come le informazioni sono ordinate
3. **Query**: come le informazioni sono richieste

Per ora, modelli teorici e non implementativi.

## Modello Booleano
Si basa sulla teoria degli insiemi e l'algebra Booleana. Una query contiene i connettivi logici AND, OR, e NOT ed i documenti recuperati sono esclusivamente quelli che soddisfano la formula data (query).
La funzione di similarità tra documento e query può quindi valere $1$ se c'è corrispondenza o $0$ altrimenti.

Tale modello è facile da comprendere ma difficile da usare per l'utente finale che potrebbe non avere chiaro il significato effettivo degli operatori; inoltre non è facile dare un ranking ai documenti solo in base al match, ed i match devono essere **esatti**, cioè soddisfare la query nella sua interezza.

## Modello spazio vettoriale
Dato che match e pesi (per il ranking) binari sono inadeguati, si propone il modello spazio vettoriale per ovviare a queste criticità.

In questo modello i documenti sono posti in uno spazio $t-dimensionale$, dove ad ogni dimensione corrisponde un termine. Un documento in questo spazio è rappresentato da un vettore le cui componenti sono date dai termini presenti al suo interno moltiplicati per un certo peso.

$$d_j = (w_{1, j}, w_{2, j}, \dots, w_{t, j})$$

I vettori associati ai termini sono indipendenti, cioè i termini appaiono nei documenti indipendentemente rispetto a ciascun altro. In realtà questo non è vero, ma non presenta un problema per il modello.

La similarità tra due documenti è data dall'angolo tra le loro **direzione**: se i vettori sono allineati, la similarità vale 1, altrimenti decresce fino a 0 quando sono ortogonali (indipendenti).

Anche query può essere immaginata come un vettore: così facendo il problema del recupero di documenti si riduce a trovare più simili (con la stessa direzione) della query. Così facendo, è possibile ottenere anche il ranking in base alla distanza della direzione tra documenti e query.

La **similarità** è data da 

$$sim(d_j, q) = \frac{\sum_{i=1}^t (w_{i,j}\cdot w_{i,1})}
{\sqrt{\sum_{i=1}^t w_{i,j}^2} \cdot \sqrt{\sum_{i=1}^t w_{i,q}^2}}$$

dove, considerando pesi binari:
- $\sum_{i=1}^t (w_{i,j}\cdot w_{i,1})$ è la somma dei valori che sono presenti sia nella query che nel documento $d_j$: se entrambi valgono 1 (sono presenti in query e documento) il prodotto è 1, altrimenti è zero.
- $\sqrt{\sum_{i=1}^t w_{i,j}^2} \cdot \sqrt{\sum_{i=1}^t w_{i,q}^2}$ sono le norme (lunghezze) dei vettori. Dividendo per questo valore il risultato è normalizzato, altrimenti documenti più lunghi sarebbero più rilevanti. Il secondo termine può anche essere ignorato, in quanto la norma della query è costante.

Il valore della similarità varia tra 0 e 1.

## TF.IDF
I pesi binari per i termini non rappresentano bene quanto un termine è significante per un documento. L'importanza di un termine è data da:
1. quante volte un termine occorre un documento $\Rightarrow$ il valore di $w$ **aumenta**, ed è direttamente proporzionale a quante volte il termine è presente nel documento.
2. in quanti documenti il termine occorre $\Rightarrow$ il valore di $w$ **diminuisce**, ed è inversamente proporzionale al numero di documenti che contengono il termine. Questo perché un termine che occorre in molti documenti ha meno potere discriminante.

La metrica che racchiude questi due criteri è definita come **Term Frequency - Inverse Document Frequency**, o **(TF.IDF)**. È data da

$$tf(i, j) = \frac{freq(i, j)}{max_{k_l \in d_j} freq(l, j)}$$
$$idf(i) = log \frac{N}{n_i}$$

dove:
- $freq(i, j)$ è il numero di occorrenze di $k_i$ in $d_j$.
- $max_{k_l \in d_j} freq(l, j)$ è la frequenza del termine che appare più volte nel documento.
- $n_i$ è il numero di documenti contenente il termine $k_i$.

Il peso per i singoli termini è dunque dato da

$$w_{i, j} = tf(i, j) \cdot idf(i)$$

Da notare che il valore di $idf$ è uguale per tutti i documenti e basta calcolarlo una sola volta. Il logaritmo applicato al termine indebolisce il suo effetto sul peso finale ($N$ potrebbe essere molto grande).

Alcune ottimizzazioni vengono fatte per il calcolo del $tf.idf$ sulla query: aggiungendo una costante ogni termine ha un valore di almeno $0.5$.

## Teorema di Bayes

$$p(C|I) = p(C) \cdot value $$

"La probabilità posteriore è data dalla probabilità precedente moltiplicata per un qualche valore"
Se il "qualche valore" è > 1 la probabilità aumenta, altrimenti diminuisce.

Il valore è dato da $p(I|C) / p(I)$: 
- $p(I)$ è la probabilità dell'evento $I$.
- $p(I|C)$ è la proprietà che $I$ accada se $C$ è vera.

$$p(C|I) = \frac{p(C) \cdot p(I|C)}{p(I)}$$

Se $P(I)$ è un evento raro e succede, allora la probabilità posteriore aumenta, mentre se $p(I|C)$ è raro, la probabilità diminuisce (se è difficile I dato C sia vero, allora anche la probabilità a posteriori cresce poco).

## Modello probabilistico (Binary Independence Model)
Data una query, il modello probabilistico stima per ogni documento nella collezione la probabilità che questo sia rilevante in base a termini nel documento, termini nella query, rilevanza attribuita e applicazione della legge di Bayes.
La probabilità è poi usata per dare un ranking ai documenti recuperati.

La probabilità di un dato documento di essere rilevante per la query q senza ulteriori informazioni è data da $p(R)$.
La probabilità che uno specifico documento $d_j$ sia rilevante è data da $p(R | d_j)$.
La probabilità che un documento estratto casualmente dalla collezione sia esattamente $d_j$ è $p(d_j)$.
La probabilità che un documento estratto casualmente tra quelli rilevanti sia esattamente $d_j$ è $p(d_j | R)$.

Le probabilità di non rilevanza sono date allo stesso modo considerando $\bar{R}$ al posto di $R$. Nota che $p(\bar{R}) = 1 - p(R)$.

Tenendo in considerazione queste probabilità, la similarità tra un documento $d_j$ e $q$ è data da

$$sim(d_j, q) = \frac{p(R|d_j)}{p(\bar{R}|d_j)}$$

Un documento è simile alla query se ha un'alta probabilità di rilevanza ed una bassa probabilità di non rilevanza.

$p(R|d_j)$ e $p(\bar{R}|d_j)$ sono sconosciute, ma si può usare il teorema di Bayes per ottenerle:

$$sim(d_j,q) 
= \frac{\frac{p(R) \cdot p(d_j | R)}{p(d_j)}}{\frac{p(\bar{R})\cdot p(d_j | \bar{R})}{p(d_j)}} 
= \frac{p(R)}{p(\bar{R})}\cdot \frac{p(d_j | R)}{p(d_j | \bar{R})}$$ 

Si noti che la probabilità $p(d_j)$ (probabilità che un documento casuale sia $d_j$) non è importante.
Se il numeratore è grande (alta probabilità che il documento sia rilevante) allora la similarità è più alta; se il denominatore è piccolo (bassa probabilità che il documento non sia rilevante) allora la similarità aumenta.

Si noti anche che $p(R)$ e $p(\bar{R})$ sono indipendenti dai documenti (costanti per tutti i documenti) e possono quindi essere rimossi per semplificazione:

$$sim(d_j,q) \cong \frac{p(d_j | R)}{p(d_j | \bar{R})}$$ 

$p(d_j | R)$ e $p(d_j | \bar{R})$ devono ancora essere approssimati, poiché non abbiamo $R$ (non sappiamo quali documenti siano effettivamente rilevanti).

### Rappresentazione documento come insieme di features
Nei documenti testuali, le features di un documento sono i suoi termini. Un documento può quindi essere definito come 

$$d_j = \{k_1, k_2, k_3, \dots\}$$

Possiamo dunque definire $p(d_j | R)$ e $p(d_j | \bar{R})$ come

$$p(d_j | R) = p(\{k_1, k_2, k_3, \dots\} | R)$$
$$p(d_j | \bar{R}) = p(\{k_1, k_2, k_3, \dots\} | \bar{R})$$

Le features $k_i$ sono:
1. **Binarie**: 1 se presenti nel documento, 0 altrimenti.
2. **Indipendenti**: la probabilità di una feature in un documento non dipende dalla probabilità delle altre feature.

L'indipendenza permette di scomporre la probabilità in un prodotto di probabilità:

$$p(d_j | R) = p(k_1 | R) \cdot p(k_2 | R) \cdot \dots = \prod_i p(k_i | R)$$

dove: 
- $p(k_i | R)$ rappresenta la probabilità che un documento scelto tra i rilevanti contenga la feature $k_i$. Il termine può essere riutilizzato per tutti i documenti che contengono la feature $k_i$ .

La similarità con la query può quindi essere riscritta come 

$$sim(d_j,q) \cong \frac{p(d_j | R)}{p(d_j | \bar{R})} 
= \prod_{k_i \in q} \frac{p(k_i | R)}{p(k_i | \bar{R})}$$ 

Tra tutti i termini $k_i$ consideriamo solo i termini presenti nella query: tutti gli altri hanno la stessa probabilità di apparire in documenti rilevanti e non rilevanti.

Infine, considerando anche il documento $d_j$ ed i termini presenti in esso otteniamo

$$sim(d_j,q) = \prod_{k_i \in q \cap d_j} \frac{p(k_i | R) \cdot p(\bar{k_i} | \bar{R})}
{p(k_i | \bar{R}) \cdot p(\bar{k_i} | R)}$$ 

dove $\bar{k_i}$ indica che il termine $k_i$ non è presente nel documento $d_j$.
Dato che abbiamo bisogno del ranking (ordinamento monotono) applichiamo il logaritmo al prodotto:

$$sim(d_j,q) = \sum_{k_i \in q \cap d_j} log \frac{p(k_i | R) \cdot p(\bar{k_i} | \bar{R})}
{p(k_i | \bar{R}) \cdot p(\bar{k_i} | R)}$$ 

Da notare che:
- il numeratore **cresce** se è probabile che il termine $k_i$  appartiene ai documenti rilevanti e $k_i$ *non* appartiene ai termini non rilevanti.
- il denominatore **diminuisce** se non è probabile che il termine appartiene ai documenti rilevanti e se non è probabile che il termine *non* non appartiene ai termini rilevanti.

È necessario capire come stimare le probabilità. Possiamo effettuare la stima in due momenti differenti: all'**inizio** e dopo il **feedback di rilevanza**.

1. Inizialmente dopo la specifica della query, possiamo definire $p(k_i | R)$ come $0.5$ (tutti i documenti hanno la stessa probabilità di essere in un documento rilevante) e $p(k_i | \bar{R})$ come $\frac{n_i}{N}$ con $n_i$ = numero documenti contenenti il termine $k_i$ (inizialmente, quasi tutti i documenti sono rilevanti, cioè molti pochi documenti nella collezione contengono il termine ricercato). Con queste approssimazioni otteniamo un **primo ranking**.
2. Dopo il feedback (l'utente ha valutato se i documenti forniti sono rilevanti o meno) possiamo rivalutare i due termini della similarità come segue:

$$p(k_i | R) = \frac{VR_i + 0.5}{VR + 1}$$
$$p(k_i | \bar{R}) = \frac{V_i - VR_i + 0.5}{V - VR + 1}$$

dove: 
- $VR_i$ è il numero di documenti valutati come rilevanti e contenenti  $k_i$.
- $V_i$ è il numero totale di documenti valutati e contenenti  $k_i$.
- $VR$ è il numero di documenti valutati come rilevanti.
- $V$ è il numero totale di documenti valutati.
- Le costanti $0.5$ e $1$ sono usate solo per evitare divisioni per zero e per normalizzazione.