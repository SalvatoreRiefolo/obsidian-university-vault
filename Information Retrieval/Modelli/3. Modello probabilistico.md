## Teorema di Bayes

$$p(C|I) = p(C) \cdot value $$

"La probabilità posteriore è data dalla probabilità precedente moltiplicata per un qualche valore"
Se il "qualche valore" è > 1 la probabilità aumenta, altrimenti diminuisce.

Il valore è dato da $p(I|C) / p(I)$: 
- $p(I)$ è la probabilità dell'evento $I$.
- $p(I|C)$ è la proprietà che $I$ accada se $C$ è vera.

$$p(C|I) = \frac{p(C) \cdot p(I|C)}{p(I)}$$

Se $P(I)$ è un evento raro e succede, allora la probabilità posteriore aumenta, mentre se $p(I|C)$ è raro, la probabilità diminuisce (se è difficile $I$ dato $C$ sia vero, allora anche la probabilità a posteriori cresce poco).

## Modello probabilistico (Binary Independence Model)
Data una query, il modello probabilistico stima per ogni documento nella collezione la probabilità che questo sia rilevante in base a termini nel documento, termini nella query, rilevanza attribuita e applicazione della legge di Bayes.
La probabilità è poi usata per dare un ranking ai documenti recuperati.

La probabilità di un dato documento di essere rilevante per la query q senza ulteriori informazioni è data da $p(R)$.
La probabilità che uno specifico documento $d_j$ sia rilevante è data da $p(R | d_j)$.
La probabilità che un documento estratto casualmente dalla collezione sia esattamente $d_j$ è $p(d_j)$.
La probabilità che un documento estratto casualmente tra quelli rilevanti sia esattamente $d_j$ è $p(d_j | R)$.

Le probabilità di non rilevanza sono date allo stesso modo considerando $\bar{R}$ al posto di $R$. Nota che $p(\bar{R}) = 1 - p(R)$.

Tenendo in considerazione queste probabilità, la similarità tra un documento $d_j$ e $q$ è data da

$$sim(d_j, q) = \frac{p(R|d_j)}{p(\bar{R}|d_j)}$$

Un documento è simile alla query se ha un'alta probabilità di rilevanza ed una bassa probabilità di non rilevanza.

$p(R|d_j)$ e $p(\bar{R}|d_j)$ sono sconosciute, ma si può usare il teorema di Bayes per ottenerle:

$$sim(d_j,q) 
= \frac{\frac{p(R) \cdot p(d_j | R)}{p(d_j)}}{\frac{p(\bar{R})\cdot p(d_j | \bar{R})}{p(d_j)}} 
= \frac{p(R)}{p(\bar{R})}\cdot \frac{p(d_j | R)}{p(d_j | \bar{R})}$$ 

Si noti che la probabilità $p(d_j)$ (probabilità che un documento casuale sia $d_j$) non è importante.
Se il numeratore è grande (alta probabilità che il documento sia rilevante) allora la similarità è più alta; se il denominatore è piccolo (bassa probabilità che il documento non sia rilevante) allora la similarità aumenta.

Si noti anche che $p(R)$ e $p(\bar{R})$ sono indipendenti dai documenti (costanti per tutti i documenti) e possono quindi essere rimossi per semplificazione:

$$sim(d_j,q) \cong \frac{p(d_j | R)}{p(d_j | \bar{R})}$$ 

$p(d_j | R)$ e $p(d_j | \bar{R})$ devono ancora essere approssimati, poiché non abbiamo $R$ (non sappiamo quali documenti siano effettivamente rilevanti).

### Rappresentazione documento come insieme di features
Nei documenti testuali, le features di un documento sono i suoi termini. Un documento può quindi essere definito come 

$$d_j = \{k_1, k_2, k_3, \dots\}$$

Possiamo dunque definire $p(d_j | R)$ e $p(d_j | \bar{R})$ come

$$p(d_j | R) = p(\{k_1, k_2, k_3, \dots\} | R)$$
$$p(d_j | \bar{R}) = p(\{k_1, k_2, k_3, \dots\} | \bar{R})$$

Le features $k_i$ sono:
1. **Binarie**: 1 se presenti nel documento, 0 altrimenti.
2. **Indipendenti**: la probabilità di una feature in un documento non dipende dalla probabilità delle altre feature.

L'indipendenza permette di scomporre la probabilità in un prodotto di probabilità:

$$p(d_j | R) = p(k_1 | R) \cdot p(k_2 | R) \cdot \dots = \prod_i p(k_i | R)$$

dove: 
- $p(k_i | R)$ rappresenta la probabilità che un documento scelto tra i rilevanti contenga la feature $k_i$. Il termine può essere riutilizzato per tutti i documenti che contengono la feature $k_i$ .

La similarità con la query può quindi essere riscritta come 

$$sim(d_j,q) \cong \frac{p(d_j | R)}{p(d_j | \bar{R})} 
= \prod_{k_i \in q} \frac{p(k_i | R)}{p(k_i | \bar{R})}$$ 

Tra tutti i termini $k_i$ consideriamo solo i termini presenti nella query: tutti gli altri hanno la stessa probabilità di apparire in documenti rilevanti e non rilevanti.

Infine, considerando anche il documento $d_j$ ed i termini presenti in esso otteniamo

$$sim(d_j,q) = \prod_{k_i \in q \cap d_j} \frac{p(k_i | R) \cdot p(\bar{k_i} | \bar{R})}
{p(k_i | \bar{R}) \cdot p(\bar{k_i} | R)}$$ 

dove $\bar{k_i}$ indica che il termine $k_i$ non è presente nel documento $d_j$.
Dato che abbiamo bisogno del ranking (ordinamento monotono) applichiamo il logaritmo al prodotto:

$$sim(d_j,q) = \sum_{k_i \in q \cap d_j} log \frac{p(k_i | R) \cdot p(\bar{k_i} | \bar{R})}
{p(k_i | \bar{R}) \cdot p(\bar{k_i} | R)}$$ 

Da notare che:
- il numeratore **cresce** se è probabile che il termine $k_i$  appartiene ai documenti rilevanti e $k_i$ *non* appartiene ai termini non rilevanti.
- il denominatore **diminuisce** se non è probabile che il termine appartiene ai documenti rilevanti e se non è probabile che il termine *non* non appartiene ai termini rilevanti.

È necessario capire come stimare le probabilità. Possiamo effettuare la stima in due momenti differenti: all'**inizio** e dopo il **feedback di rilevanza**.

1. Inizialmente dopo la specifica della query, possiamo definire $p(k_i | R)$ come $0.5$ (tutti i documenti hanno la stessa probabilità di essere in un documento rilevante) e $p(k_i | \bar{R})$ come $\frac{n_i}{N}$ con $n_i$ = numero documenti contenenti il termine $k_i$ (inizialmente, quasi tutti i documenti sono rilevanti, cioè molti pochi documenti nella collezione contengono il termine ricercato). Con queste approssimazioni otteniamo un **primo ranking**.
2. Dopo il feedback (l'utente ha valutato se i documenti forniti sono rilevanti o meno) possiamo rivalutare i due termini della similarità come segue:

$$p(k_i | R) = \frac{VR_i + 0.5}{VR + 1}$$
$$p(k_i | \bar{R}) = \frac{V_i - VR_i + 0.5}{V - VR + 1}$$

dove: 
- $VR_i$ è il numero di documenti valutati come rilevanti e contenenti  $k_i$.
- $V_i$ è il numero totale di documenti valutati e contenenti  $k_i$.
- $VR$ è il numero di documenti valutati come rilevanti.
- $V$ è il numero totale di documenti valutati.
- Le costanti $0.5$ e $1$ sono usate solo per evitare divisioni per zero e per normalizzazione.

## BM 25 (Best Match 25)

Estensione di BIM che considera la frequenza dei termini in documenti e query e la lunghezza dei documenti. 
Si aggiungono all'equazione della similarità di BIM anche i **fattori TF per documenti e query**. Questi crescono limitatamente (circa in modo logaritmico) rispetto alla frequenza dei termini.